---
title: 
layout: default
---

# Spinning Up GPUs on AWS

Scaling out over many cores is the only way to train deep neural networks in a reasonable amount of time. Deeplearning4j can parallelize the massive linear algebra operations necessary for processing large and high-dimensional datasets on multiple GPUs. Indeed, it scales to use an arbitrary number of GPUs, as many as you have available. 

Short of building their own GPU rack, most DL4J users will run neural nets over multiple GPUs via Amazon Web Services, and AWS allows users to access up to 1,536 CUDA cores at once. While owning your own chips allows for greater optimization, GPUs on AWS gives a taste of their processing speed. 

AWS provides instructions for launching GPU instances for a variety of NVIDIA drivers [here](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using_cluster_computing.html).




