---
title:
layout: zh-default
---

# 卷积网络

目录

* <a href="#intro">卷积网络简介</a>
* <a href="#tensors">图像即四维张量？</a>
* <a href="#define">卷积网络的定义</a>
* <a href="#work">卷积网络如何运行</a>
* <a href="#max">特征汇总/降采样</a>
* <a href="#code">DL4J代码示例</a>
* <a href="#resource">其他资源</a>

## <a name="intro">卷积网络简介</a>

卷积网络对图像进行物体辨识，可识别人脸、人类个体、道路标志、茄子、鸭嘴兽以及视觉数据中诸多其他方面的内容。卷积网络与运用光学字符辨识进行的文本分析有重合之处，但也可用于对离散文本单元以及声音形式的文本进行分析。

卷积网络（ConvNets）在图像辨识上的效能，是如今全球对深度学习产生兴趣的重要原因。卷积网络正推动机器视觉的大幅进步，在包括自动驾驶汽车、机器人、无人机和对视觉障碍人士的诊治方面，均具有显而易见的应用价值。

## <a name="tensors">图像即四维张量？</a>

卷积网络将图像摄取并处理为张量，张量是具有附加维度的数字矩阵。

由于难以对张量进行形象描述，以下将通过类比进行解释。标量是普通数字，比如7；而矢量是一串数字（例如`[7,8,9]`）；而矩阵是像电子表格一样横纵排列的数字直角坐标网。按几何学概念来看，如果标量是零维定点，那么矢量就是一维的线，矩阵就是一个二维平面，一堆矩阵就是三维立方体，当这些矩阵的每个元素都附着大量的特征图谱，那便进入到了四维空间，下面是一个2x2矩阵示例：

    [ 1, 2 ]
    [ 5, 8 ]

张量涵括了二维平面以上的维度。通过按立方体排列的一列数字，很轻易就能绘制一个三维张量。所示为2x3x2张量的呈现模式（沿着Z轴绘制的每个二元数组的底元素，其直观地反应了三维数组）：

![Alt text](../img/tensor.png)

上述张量可以用代码表示为：`[[[2,3],[3,5],[4,7]],[[3,4],[4,6],[5,8]]].` 请见示意图：

![Alt text](../img/3d_matrix_cube.png)

换言之，张量的形成原理为数组嵌套数组，因为随机数字组成的维度远远比我们空间上所见到的要广泛的多，这种嵌套模式是可以无限持续的。四维张量可以通过嵌套了更深层次的数组轻易取代任何标量。卷积网络对四维张量的处理如下所示（注意嵌套数组）。

![Alt text](../img/3d_matrix.png)

ND4J和Deeplearning4J同义使用`NDArray`和张量。一个张量的维度`(1,2,3…n)`被称为“阶”。例如，第五阶张量有五个维度。

图像的宽度和高度很容易理解。由于颜色的编码方式，必须有一个“深度”。例如，根据红-绿-蓝（RGB）编码可制作一个三层深度的图像。每层叫作一个“通道”，通过卷积，只需按照时间本身的脉络便可制作存在于第四维的大量特征图谱。（卷积网络制作的特征图谱只是图像的细节表现，以直线或曲线的形式出现。）

卷积网络将图像按照四维实体处理而不是将其归类于二维领域。这些概念将在下文探究。

## <a name="define">定义</a>

在拉丁文中，*convolvere* 和 *to convolve* 是卷在一起的意思。在数学应用里，一个卷积是指用来计算两个函数相互重叠时的积分值。卷积可以视为两个函数的相乘。

设想一条又高又窄的贝尔曲线位于曲线图的中部。曲线下的区域则是积分值。设想该条曲线附近有第二条更短更宽的贝尔曲线，从左至右在曲线图中缓慢漂移。这两个函数沿着X轴重叠的定点则是一个[卷积](http://mathworld.wolfram.com/Convolution.html)。所以，一定意义上，两个函数是“卷”在了一起。

静态底层函数是待分析的输入图像，第二个动态函数被称为“过滤器”，因为它负责筛选图像的信号。两个函数通过乘法运算联系在一起。卷积应该被视为矩阵而不是贝尔曲线。直观图像请见“卷积演示”下[安德鲁·卡帕西的极佳动画演示](https://cs231n.github.io/convolutional-networks/)。

我们还需明确，在卷积网络中，一张图像需经过多个过滤器，每个过滤器筛选一个不同的信号。在较早层里，可以将其想象成经过水平线过滤器、垂直线过滤器和斜角线过滤器，得出的数据随即在图谱中构成图像的边缘。

卷积网络将这些过滤器筛选出的图像特征空间片段逐一绘制，并制作了具有各个部位特征的图谱。通过研究特征空间的不同比例，卷积网路可以轻松地构建可扩展且稳健的特征工程。

（注意：卷积网络分析图像采用的原理和RBM不同，RBM将图像视为一个整体进行特征的修复和识别，而卷积网络则通过我们所说的特征图谱片段进行图像分析。）

于是卷积网络执行搜索。想象一个小型的放大镜在图像上从左向右滑动，一遍后再从左边重复开始操作（如打字机一般）。在移动窗口中唯一可见的是一截短垂直线。三个暗像素相互堆叠。垂直线辨识过滤器在图像的实际像素上移动并寻求匹配。

每次成功的匹配将被绘制在特征空间的视觉元素上。在那个空间里，每个垂直线匹配的位置会被完整记录下来，就像鸟类观测员每次发现大蓝鹭都会在地图上用大头针标记出来。卷积网络需要在一张单一图像上运行很多次搜索——水平线，垂直线，有多少视觉元素就需要搜索多少次。

卷积网络在输入时比卷积本身要执行更多的操作。

在经过卷积层处理后，输入还需经过一次非线性转换，例如*tanh*或者*rectified linear*单元，使输入值的范围压缩到-1至1之间。

## <a name="work">卷积网络如何运行</a>

首先我们要知道的是卷积网络和人类认知图像的方式不一样。因此，需要从不同的角度去看待图像的含义以及卷积网络如何处理图像。

卷积网络将图像视为立体的量，例如三维物体，而不是可以用宽高测量的平面画布。这是因为数码色彩图像有红-绿-蓝（RGB）编码，将这三色混合可以得出我们肉眼可见的色谱。卷积网络将这些图像以三个分别的互相堆叠的颜色收集起来。

所以卷积网络把正常颜色的图像当作矩形件收集起来，其宽度和高度均可用像素和维度测量，其深度是三阶深度，取其首字母为RGB。这些深度层被称为*通道*。

我们用输入量和输出量来描述经过卷积网络处理的图像，用数学形式中的多维矩阵表示为：30x30x3。每个阶层维度的变化原因详见下文。

需要密切关注图像每个维度的精确测量结果，因为他们是用来处理图像的线性代数操作的基础。

在图像的每个像素中，R、G、B的强度将会以数据的形式表示出来，而且由三者中的某一要素和二维矩阵构成的数据一同构成图像的量。

这些数据是输入到卷积网络中最原始的感官特征，卷积网络的目的则是在那些数据中找出那些能帮助准确分辨图像的重要信号。（就像我们讨论过的其他正反馈一样。）

卷积网络并非逐个像素处理，而是把许多像素吸入一个小片并把他们放入一个*过滤器*中过滤。过滤器是一个比图像小的方针，跟小片差不多大小，也叫作*内核*，它在发现类似支持向量的机件时会产生提示。过滤器的工作是在像素中找到样式。

<iframe src="https://cs231n.github.io/assets/conv-demo/index.html" width="100%" height="700px;" style="border:none;"></iframe>

*感谢[安德鲁·卡帕西](https://cs231n.github.io/)提供这一的极佳动画演示。*

设想有两个矩阵，一个是30x30，另一个是3x3。也就是说，过滤器覆盖了在图像“通道”表面的十分之一。

我们要用这个图像通道小片获取过滤器的点积。如果两个矩阵在同一位置都有较高的值，则点积输出会很高。如果并非如此，则输出会很低。用这种方式，我们可以通过点积输出的一个单值来确定相应图像的像素样式是否与过滤器表达出来的像素样式吻合。

设想我们的过滤器在水平线上显示第二排的值很高而第一和第三排的值很低。现在从相应图像左上角绘制，然后逐步移动图像上的过滤器直到到达右上角。移动的尺寸被称为*步幅*。可以从右边开始移动过滤器，也可以选择更大的步伐。

在每一步中，你需要获取另一个点积，并将点积结果置于被称为*激活图谱*的第三个矩阵中。激活图谱上的宽度或者量数都应该与过滤器在相应图像上移动的步数一致。因为步幅一大步子就少，根据大的步幅制作的激活图谱也会相应变小。这一点非常重要，因为卷积网络在每个层制作的矩阵大小直接和他们的计算结果与所花时间挂钩。较大的步幅意味着花的时间更少，计算量较小。

重叠在前三排上的过滤器将会滑过1-3排，然后继续开始滑过同个图像的4-6排。如果步幅为三，那么制作的点积矩阵为10x10。同个水平线的过滤器可以在相应图像的所有R、G、B三列通道上应用。三个10x10的激活图谱可以相加，所以在相应图像的三列轨道上水平线制成的聚集激活图谱仍是10x10。

现在，因为图像有不同方向的线和包含不同形状以及像素样式，你会希望在相应的图像上滑动其他过滤器以搜索那些样式。例如，你可以在像素里寻找96种不同的样式。这96种样式会构成96张激活图谱，新结果则为10x10x96。在下图中，为了使我们更明了，会对输入图像、内核和输出的激活图谱重新标号。

![Alt text](../img/karpathy-convnet-labels.png)

我们刚才描述的即是卷积。你可以把卷积想成是信号处理形式的另一种奇特的乘法运算。也可以想成两个点积产生的两个矩阵是两个函数。图像就是底层函数，而过滤器就它上面“卷”的函数。

<iframe src="http://mathworld.wolfram.com//images/gifs/convgaus.gif" width="100%" height="250px;" style="border:none;"></iframe>

一个主要的问题是高维度的图像会花费我们很多时间以及需要运算很多次。卷积网络就是为了通过不同方式降低图像的维度而设计的。过滤器步幅也是减少维度的方法，另一种方法是降采样。

## <a name="max">特征汇总/降采样</a>

卷积网络的下一层有三个名字：特征汇总、降采样和二次抽样。激活图谱像卷积一样运用到降采样层，这种方法适用于每次一小片。在这种情况下，特征汇总只取图像里每一片的最大值，将其置于存有其他片区最大值的一个矩阵里，并舍弃激活图谱里其他信息。

![Alt text](../img/maxpool.png)
*感谢[安德鲁·卡帕西](https://cs231n.github.io/)供图。*

只有在图像里与特征（最大值）最相关的点才被保留，然后那些最大值组合构成一个低维空间。

在这一步许多低值的信息的损失促使研究采用替代的方法。但是降采样也有其优点，尤其是需要进行信息丢失或数据储值减少的研究时。

### 交流层

以下展示了典型卷积网络的转换顺序。

![Alt text](../img/convnet.png)

从左至右你会看到：

* 扫描实际输入图像特征。光矩形是正经过的过滤器；
* 激活图谱是彼此重叠的，逐一对照你所采用的过滤器，最大的矩形是降采样的片区；  
* 通过降采样压缩的激活图谱；
* 让过滤器通过第一个降采样堆而创建的一组新激活图谱；
* 第二次降采样，压缩第二组激活图谱；
* 一个用节点标签对输出进行分类的完全连接层；

因为越来越多信息的流失，卷积网络处理的样式变得更抽象，且和肉眼可见样式差别原来越大。所以如果随着卷积网络的深入发展其未能提供容易的直觉知识，只是因为肉眼已经无法分辨其模式了，请忘记自己的和忘记我们的直觉，

## <a name="code">DL4J编码举例</a>

这是一个如何通过Deeplearning4j配置卷积网络的例子：

<script src="http://gist-it.appspot.com/https://github.com/deeplearning4j/dl4j-0.4-examples/blob/master/src/main/java/org/deeplearning4j/examples/convolution/CNNMnistExample.java?slice=36:109"></script>

## <a name="resource">其他资源</a>

* 纽约大学教授、Facebook研究主管[扬·莱坤](http://yann.lecun.com/exdb/publis/pdf/lecun-iscas-10.pdf)对机器视觉任务中常用的卷积网络使用的推动和发展贡献良多。
* [安德鲁·卡帕西的斯坦福大学课程](https://cs231n.github.io/)讲授卷积网络，相当精彩。我们强烈推荐将之作为卷积网络重要概念的入门。(*Python练习。*)
* [此处为我们卷积网络的Github测试](https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-core/src/test/java/org/deeplearning4j/models/layers/ConvolutionDownSampleLayerTest.java)。
* 欲一睹DL4J卷积网络的运作，请根据[快速开始页](http://deeplearning4j.org/quickstart.html)的指示运行我们的[案例](https://github.com/deeplearning4j/dl4j-0.0.3.3-examples/tree/master/src/main/java/org/deeplearning4j/convolution)。
* [递归网络简介](../recurrentnet.html)
* [限制玻尔兹曼机指南](../restrictedboltzmannmachine.html)
* [神经网络简介](../neuralnet-overview.html)
